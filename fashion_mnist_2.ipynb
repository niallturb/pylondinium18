{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fashion_mnist_2.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"UflUmQ6J4mBe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","from numpy.random import seed\n","seed(125)\n","from tensorflow import set_random_seed\n","set_random_seed(125)\n","import keras\n","from keras.datasets import fashion_mnist\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Activation, Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from keras.layers.normalization import BatchNormalization"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zqb-vhkQGOYH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# The most robust way to report results and compare models is to repeat your experiment many times (30+) \n","# and use summary statistics.\n","\n","\n","from numpy.random import seed\n","seed(125)\n","from tensorflow import set_random_seed\n","set_random_seed(125)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Orq-nvMYBazw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# FASHION_MNIST class\n","\n","class FASHION_MNIST():\n","  \n","    def __init__(self,\n","                 img_rows=28, \n","                 img_cols=28,\n","                 num_classes=10,\n","                 l1_out=32, \n","                 l2_out=64,\n","                 l3_out=128,\n","                 l4_out=128,\n","                 l1_drop=0.25, \n","                 l2_drop=0.25,\n","                 l3_drop=0.4,\n","                 l4_drop=0.3,\n","                 batch_size=256, \n","                 epochs=50, \n","                 validation_split=0.2):\n","      \n","        self.__img_rows = img_rows\n","        self.__img_cols = img_cols\n","        self.__num_classes = num_classes\n","        self.l1_out = l1_out\n","        self.l2_out = l2_out\n","        self.l3_out = l3_out\n","        self.l4_out = l4_out\n","        self.l1_drop = l1_drop\n","        self.l2_drop = l2_drop\n","        self.l3_drop = l3_drop\n","        self.l4_drop = l4_drop        \n","        self.batch_size = batch_size\n","        self.epochs = epochs\n","        self.validation_split = validation_split\n","        self.__X_train, self.__X_test, self.__y_train, self.__y_test = self.load_process_data()\n","        self.__model = self.fashion_mnist_model()\n","        \n","\n","    # load and process Fashion MNIST data (can load from Keras)  \n","    def load_process_data(self):\n","      \n","        (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n","\n","        # Preprocess input data for Keras\n","\n","        # Each image is 28x28 pixels\n","        # Specify input shape sutable for Keras\n","        # to be used as input image dimensions\n","        input_shape = (self.__img_rows, self.__img_cols, 1)\n","\n","        # When using the Theano backend, you must explicitly declare a dimension for the depth of the input image. \n","        # For example, a full-color image with all 3 RGB channels will have a depth of 3\n","        # As the fashion mnist images are in black and white, only have a depth of 1\n","\n","        # Reshape input data\n","        # Want to transform the dataset from having shape (n, width, height) to (n, width, height, depth)\n","        X_train = X_train.reshape(X_train.shape[0], self.__img_rows, self.__img_rows, 1)\n","        X_test = X_test.reshape(X_test.shape[0], self.__img_rows, self.__img_cols, 1)\n","\n","        # Convert input data to float32\n","        X_train = X_train.astype('float32')\n","        X_test = X_test.astype('float32')\n","\n","        # Normalize data values to the range [0,1]\n","        # note: Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black)\n","        X_train /= 255\n","        X_test /= 255\n","\n","        # For the output, we change number to one-hot vector. \n","        y_train = to_categorical(y_train, 10)\n","        y_test = to_categorical(y_test, 10)\n","\n","        return X_train, X_test, y_train, y_test\n","\n","      \n","    # specify Fashion MNIST model architecture\n","    def fashion_mnist_model(self):\n","      \n","        model = Sequential()        \n","        \n","        # First convolution layer\n","        model.add(Conv2D(filters=self.l1_out, \n","                         kernel_size=(3, 3),\n","                         kernel_initializer='he_normal',\n","                         input_shape=(self.__img_rows, self.__img_cols, 1)))\n","        model.add(Activation('relu'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(self.l1_drop))\n","\n","        # Second convolution layer\n","        model.add(Conv2D(filters=self.l2_out, \n","                         kernel_size=(3, 3)))\n","        model.add(Activation('relu'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(self.l2_drop))\n","        \n","        # Third convolution layer\n","        model.add(Conv2D(filters=self.l3_out, \n","                         kernel_size=(3, 3)))\n","        model.add(Activation('relu'))\n","        model.add(Dropout(self.l3_drop))\n","\n","        # Dense layer\n","        model.add(Flatten())\n","        model.add(Dense(units=self.l4_out))\n","        model.add(Activation('relu'))\n","        model.add(Dropout(self.l4_drop))\n","        \n","        model.add(Dense(self.__num_classes))\n","        model.add(Activation('softmax'))\n","        \n","        model.compile(loss='categorical_crossentropy',\n","                      optimizer=Adam(),\n","                      metrics=['accuracy'])\n","        \n","        return model\n","\n","    \n","    # fit mnist model\n","    def fit(self):\n","      \n","        early_stopping = EarlyStopping(patience=4, verbose=1)\n","        \n","        self.__model.fit(self.__X_train, self.__y_train,\n","                                     batch_size=self.batch_size,\n","                                     epochs=self.epochs,\n","                                     verbose=1,\n","                                     validation_split=self.validation_split,\n","                                     callbacks=[early_stopping])\n","    \n","    # evaluate mnist model\n","    def evaluate(self):\n","      \n","        self.fit()\n","        \n","        evaluation = self.__model.evaluate(self.__X_test,\n","                                           self.__y_test,\n","                                           batch_size=self.batch_size,\n","                                           verbose=0)\n","        \n","        return evaluation\n","      \n","      "],"execution_count":0,"outputs":[]},{"metadata":{"id":"e3Nl8pdnAtXy","colab_type":"text"},"cell_type":"markdown","source":["### Run Basic model"]},{"metadata":{"id":"LwSJLyF7AqrJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Function to run FASHION_MNIST class\n","\n","def run_fashion_mnist(img_rows=28, \n","                      img_cols=28,\n","                      num_classes=10,\n","                      l1_out=32,\n","                      l2_out=64,\n","                      l3_out=128,\n","                      l4_out=128,\n","                      l1_drop=0.25,\n","                      l2_drop=0.25,\n","                      l3_drop=0.4,\n","                      l4_drop=0.3,\n","                      batch_size=256, \n","                      epochs=50, \n","                      validation_split=0.2):\n","    \n","    fashion_mnist = FASHION_MNIST(img_rows= img_rows,\n","                                  img_cols = img_cols,\n","                                  num_classes = num_classes,\n","                                  l1_out=l1_out,\n","                                  l2_out=l2_out,\n","                                  l3_out=l3_out,\n","                                  l4_out=l4_out,\n","                                  l1_drop=l1_drop,\n","                                  l2_drop=l2_drop,\n","                                  l3_drop=l3_drop,\n","                                  l4_drop=l4_drop,\n","                                  batch_size=batch_size,\n","                                  epochs=epochs,\n","                                  validation_split=validation_split)\n","    \n","    evaluation = fashion_mnist.evaluate()\n","    \n","    return evaluation"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oZU-g7P88Wkw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1108},"outputId":"5ac18ff5-1255-4dd6-c349-2884ffeecdba","executionInfo":{"status":"ok","timestamp":1527859781414,"user_tz":-60,"elapsed":122409,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["\n","import time\n","\n","start = time.time()\n","\n","evaluation = run_fashion_mnist()\n","\n","end = time.time()\n","print(\"time elapsed: {}\".format(end - start))\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 3us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 6s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 3s 1us/step\n","Train on 48000 samples, validate on 12000 samples\n","Epoch 1/50\n","46336/48000 [===========================>..] - ETA: 0s - loss: 0.8375 - acc: 0.6884"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 6s 133us/step - loss: 0.8282 - acc: 0.6916 - val_loss: 0.5057 - val_acc: 0.8148\n","Epoch 2/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.5073 - acc: 0.8105 - val_loss: 0.4049 - val_acc: 0.8523\n","Epoch 3/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.4326 - acc: 0.8395 - val_loss: 0.3563 - val_acc: 0.8646\n","Epoch 4/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.3891 - acc: 0.8578 - val_loss: 0.3217 - val_acc: 0.8799\n","Epoch 5/50\n","36352/48000 [=====================>........] - ETA: 0s - loss: 0.3617 - acc: 0.8667"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 4s 85us/step - loss: 0.3618 - acc: 0.8670 - val_loss: 0.3066 - val_acc: 0.8843\n","Epoch 6/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.3384 - acc: 0.8747 - val_loss: 0.2868 - val_acc: 0.8910\n","Epoch 7/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.3242 - acc: 0.8814 - val_loss: 0.2821 - val_acc: 0.8938\n","Epoch 8/50\n","48000/48000 [==============================] - 4s 87us/step - loss: 0.3093 - acc: 0.8882 - val_loss: 0.2742 - val_acc: 0.8988\n","Epoch 9/50\n","35584/48000 [=====================>........] - ETA: 1s - loss: 0.2995 - acc: 0.8913"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 4s 86us/step - loss: 0.2991 - acc: 0.8911 - val_loss: 0.2687 - val_acc: 0.9003\n","Epoch 10/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.2912 - acc: 0.8920 - val_loss: 0.2532 - val_acc: 0.9062\n","Epoch 11/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.2857 - acc: 0.8950 - val_loss: 0.2516 - val_acc: 0.9079\n","Epoch 12/50\n","48000/48000 [==============================] - 4s 87us/step - loss: 0.2750 - acc: 0.8984 - val_loss: 0.2455 - val_acc: 0.9086\n","Epoch 13/50\n","34816/48000 [====================>.........] - ETA: 1s - loss: 0.2692 - acc: 0.9010"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 4s 86us/step - loss: 0.2694 - acc: 0.9007 - val_loss: 0.2457 - val_acc: 0.9105\n","Epoch 14/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.2638 - acc: 0.9040 - val_loss: 0.2397 - val_acc: 0.9103\n","Epoch 15/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.2599 - acc: 0.9035 - val_loss: 0.2413 - val_acc: 0.9106\n","Epoch 16/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.2541 - acc: 0.9066 - val_loss: 0.2315 - val_acc: 0.9148\n","Epoch 17/50\n","34816/48000 [====================>.........] - ETA: 1s - loss: 0.2506 - acc: 0.9062"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 4s 86us/step - loss: 0.2474 - acc: 0.9079 - val_loss: 0.2346 - val_acc: 0.9121\n","Epoch 18/50\n","48000/48000 [==============================] - 4s 87us/step - loss: 0.2460 - acc: 0.9082 - val_loss: 0.2253 - val_acc: 0.9161\n","Epoch 19/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.2438 - acc: 0.9085 - val_loss: 0.2260 - val_acc: 0.9141\n","Epoch 20/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.2405 - acc: 0.9099 - val_loss: 0.2229 - val_acc: 0.9169\n","Epoch 21/50\n","34816/48000 [====================>.........] - ETA: 1s - loss: 0.2307 - acc: 0.9145"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 4s 86us/step - loss: 0.2317 - acc: 0.9131 - val_loss: 0.2263 - val_acc: 0.9173\n","Epoch 22/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.2292 - acc: 0.9144 - val_loss: 0.2189 - val_acc: 0.9191\n","Epoch 23/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.2298 - acc: 0.9141 - val_loss: 0.2282 - val_acc: 0.9139\n","Epoch 24/50\n","48000/48000 [==============================] - 4s 86us/step - loss: 0.2280 - acc: 0.9140 - val_loss: 0.2217 - val_acc: 0.9177\n","Epoch 25/50\n","34560/48000 [====================>.........] - ETA: 1s - loss: 0.2283 - acc: 0.9141"],"name":"stdout"},{"output_type":"stream","text":["48000/48000 [==============================] - 4s 86us/step - loss: 0.2265 - acc: 0.9145 - val_loss: 0.2242 - val_acc: 0.9191\n","Epoch 26/50\n","48000/48000 [==============================] - 4s 85us/step - loss: 0.2180 - acc: 0.9191 - val_loss: 0.2354 - val_acc: 0.9123\n","Epoch 00026: early stopping\n","time elapsed: 121.86227059364319\n"],"name":"stdout"}]},{"metadata":{"id":"N5M7Q58J8bwv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"6389d6ce-12c6-47f8-f7bc-f97f3338fccc","executionInfo":{"status":"ok","timestamp":1527860829957,"user_tz":-60,"elapsed":509,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["print('TEST LOSS:', evaluation[0])\n","print('TEST ACCURACY:', evaluation[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["TEST LOSS: 0.2467023584008217\n","TEST ACCURACY: 0.9116\n"],"name":"stdout"}]},{"metadata":{"id":"Ip9OhOP32AqQ","colab_type":"text"},"cell_type":"markdown","source":["### Bayesian Optimization"]},{"metadata":{"id":"ZpGPCYjt0lTv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Specify bounds for hyperparameters\n","\n","# bounds dict should be in order of continuous type and then discrete type\n","\n","bounds = [{'name': 'validation_split', 'type': 'continuous',  'domain': (0.0, 0.3)},\n","          {'name': 'l1_drop',          'type': 'continuous',  'domain': (0.0, 0.5)},\n","          {'name': 'l2_drop',          'type': 'continuous',  'domain': (0.0, 0.5)},\n","          {'name': 'l3_drop',          'type': 'continuous',  'domain': (0.0, 0.5)},\n","          {'name': 'l4_drop',          'type': 'continuous',  'domain': (0.0, 0.5)},\n","          {'name': 'l1_out',           'type': 'discrete',    'domain': (16, 32, 64, 128, 256, 512)},\n","          {'name': 'l2_out',           'type': 'discrete',    'domain': (32, 64, 128, 256, 512, 1024)},\n","          {'name': 'l3_out',           'type': 'discrete',    'domain': (32, 64, 128, 256, 512, 1024)},\n","          {'name': 'l4_out',           'type': 'discrete',    'domain': (32, 64, 128, 256, 512, 1024)},\n","          {'name': 'batch_size',       'type': 'discrete',    'domain': (64, 128, 256, 512)},\n","          {'name': 'epochs',           'type': 'discrete',    'domain': (30, 40, 50, 60)}]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eee0rq5WC5d3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# function to optimize fashion mnist model\n","\n","def f(x):\n","  \n","    print(x)\n","    \n","    evaluation = run_fashion_mnist(\n","        img_rows=28, \n","        img_cols=28,\n","        num_classes=10,\n","        l1_out = int(x[:,5]),\n","        l2_out = int(x[:,6]),\n","        l3_out = int(x[:,7]),\n","        l4_out = int(x[:,8]),\n","        l1_drop = float(x[:,1]),\n","        l2_drop = float(x[:,2]),\n","        l3_drop = float(x[:,3]),\n","        l4_drop = float(x[:,4]),\n","        batch_size = int(x[:,9]),\n","        epochs = int(x[:,10]),\n","        validation_split = float(x[:,0]))\n","    \n","    print(\"TEST LOSS: {} \\t TEST ACCURACY: {}\".format(evaluation[0], evaluation[1]))\n","    print(evaluation, \"\\n\")\n","        \n","    return evaluation[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2Ptxy4uP_1nD","colab_type":"text"},"cell_type":"markdown","source":["### Optimizer instance"]},{"metadata":{"id":"6qqJEgEy_7gv","colab_type":"text"},"cell_type":"markdown","source":["Install and import GPyOpt\n","\n","http://sheffieldml.github.io/GPyOpt/"]},{"metadata":{"id":"RQOFeynaAAgF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":598},"outputId":"4df3f85f-9194-4210-8348-0d866885a566","executionInfo":{"status":"ok","timestamp":1527860893262,"user_tz":-60,"elapsed":37030,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["! pip install GPy\n","! pip install gpyopt"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting GPy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/0a/856e3d2990739ae4a4dc526a1987dbf31ae3310d051322df815147e76453/GPy-1.9.2.tar.gz (859kB)\n","\u001b[K    100% |████████████████████████████████| 860kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.14.3)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPy) (0.19.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy) (1.11.0)\n","Collecting paramz>=0.9.0 (from GPy)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/13/097b3223aff557d000b418d6ba3bdc0ca6c3ed672aefbb0e62420ca8d5ac/paramz-0.9.1.tar.gz (71kB)\n","\u001b[K    100% |████████████████████████████████| 71kB 9.7MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy) (4.3.0)\n","Building wheels for collected packages: GPy, paramz\n","  Running setup.py bdist_wheel for GPy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/36/b9/13/498e283b6081c81aded82d1c174f8c251096027be686e79005\n","  Running setup.py bdist_wheel for paramz ... \u001b[?25l-\b \b\\\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/17/72/fe/035ce71322865ed7de8a98cac33e65f464dcc2bcbcf93cf642\n","Successfully built GPy paramz\n","Installing collected packages: paramz, GPy\n","Successfully installed GPy-1.9.2 paramz-0.9.1\n","Collecting gpyopt\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/40/ca8f080d74d9f4e29069faa944fcfb083e8693b6daaba0f1e4bc65c88650/GPyOpt-1.2.5.tar.gz (55kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 2.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpyopt) (1.14.3)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from gpyopt) (0.19.1)\n","Requirement already satisfied: GPy>=1.8 in /usr/local/lib/python3.6/dist-packages (from gpyopt) (1.9.2)\n","Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->gpyopt) (0.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->gpyopt) (1.11.0)\n","Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy>=1.8->gpyopt) (4.3.0)\n","Building wheels for collected packages: gpyopt\n","  Running setup.py bdist_wheel for gpyopt ... \u001b[?25l-\b \b\\\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/33/1d/87/dc02440831ba986b1547dd11a7dcd44e893b0527083066d869\n","Successfully built gpyopt\n","Installing collected packages: gpyopt\n","Successfully installed gpyopt-1.2.5\n"],"name":"stdout"}]},{"metadata":{"id":"QmSr5Jc4ATOr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import GPy, GPyOpt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ByPtu5hF_0VO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":4287},"outputId":"484c0311-74ec-450f-e86f-4361e2a137b0","executionInfo":{"status":"ok","timestamp":1527862077428,"user_tz":-60,"elapsed":1148527,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["# optimizer\n","\n","\n","# Initialize the Bayesian Optimization method.\n","\n","# f: function to optimize\n","### should take 2-dimensional numpy arrays as input and return 2-dimensional outputs \n","# domain: \n","### list of dictionaries containing the description of the inputs variables \n","\n","import time\n","start = time.time()\n","\n","optimize_fashion_mnist = GPyOpt.methods.BayesianOptimization(f=f, \n","                                                             domain=bounds,\n","                                                             acquisition_type='EI')\n","\n","end = time.time()\n","print(\"time elapsed: {}\".format((end - start)/60))\n","\n","# time elapsed: 27.23"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[2.98574033e-01 2.95115921e-01 2.65278698e-01 1.40351954e-01\n","  4.77346610e-01 2.56000000e+02 6.40000000e+01 6.40000000e+01\n","  1.28000000e+02 1.28000000e+02 5.00000000e+01]]\n","Train on 42085 samples, validate on 17915 samples\n","Epoch 1/50\n","42085/42085 [==============================] - 14s 324us/step - loss: 0.8300 - acc: 0.6960 - val_loss: 0.4606 - val_acc: 0.8262\n","Epoch 2/50\n","25984/42085 [=================>............] - ETA: 4s - loss: 0.5221 - acc: 0.8069"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 305us/step - loss: 0.5041 - acc: 0.8159 - val_loss: 0.3860 - val_acc: 0.8555\n","Epoch 3/50\n","42085/42085 [==============================] - 13s 305us/step - loss: 0.4269 - acc: 0.8453 - val_loss: 0.3332 - val_acc: 0.8751\n","Epoch 4/50\n","40320/42085 [===========================>..] - ETA: 0s - loss: 0.3868 - acc: 0.8590"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 305us/step - loss: 0.3864 - acc: 0.8595 - val_loss: 0.3251 - val_acc: 0.8776\n","Epoch 5/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.3551 - acc: 0.8717 - val_loss: 0.2908 - val_acc: 0.8957\n","Epoch 6/50\n","42085/42085 [==============================] - 13s 305us/step - loss: 0.3342 - acc: 0.8793 - val_loss: 0.2828 - val_acc: 0.8960\n","Epoch 7/50\n"," 1152/42085 [..............................] - ETA: 11s - loss: 0.3006 - acc: 0.8863"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 304us/step - loss: 0.3207 - acc: 0.8827 - val_loss: 0.2719 - val_acc: 0.8977\n","Epoch 8/50\n","42085/42085 [==============================] - 13s 305us/step - loss: 0.3054 - acc: 0.8879 - val_loss: 0.2691 - val_acc: 0.8996\n","Epoch 9/50\n","34688/42085 [=======================>......] - ETA: 2s - loss: 0.2967 - acc: 0.8903"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 306us/step - loss: 0.2972 - acc: 0.8908 - val_loss: 0.2684 - val_acc: 0.9007\n","Epoch 10/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.2899 - acc: 0.8942 - val_loss: 0.2575 - val_acc: 0.9034\n","Epoch 11/50\n","42085/42085 [==============================] - 13s 305us/step - loss: 0.2801 - acc: 0.8980 - val_loss: 0.2562 - val_acc: 0.9069\n","Epoch 12/50\n","  128/42085 [..............................] - ETA: 13s - loss: 0.2084 - acc: 0.8984"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 303us/step - loss: 0.2731 - acc: 0.8988 - val_loss: 0.2525 - val_acc: 0.9073\n","Epoch 13/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.2632 - acc: 0.9041 - val_loss: 0.2571 - val_acc: 0.9063\n","Epoch 14/50\n","33664/42085 [======================>.......] - ETA: 2s - loss: 0.2580 - acc: 0.9049"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 305us/step - loss: 0.2578 - acc: 0.9054 - val_loss: 0.2478 - val_acc: 0.9085\n","Epoch 15/50\n","42085/42085 [==============================] - 13s 303us/step - loss: 0.2551 - acc: 0.9070 - val_loss: 0.2457 - val_acc: 0.9083\n","Epoch 16/50\n","41600/42085 [============================>.] - ETA: 0s - loss: 0.2509 - acc: 0.9085"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 304us/step - loss: 0.2511 - acc: 0.9084 - val_loss: 0.2441 - val_acc: 0.9114\n","Epoch 17/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.2496 - acc: 0.9082 - val_loss: 0.2397 - val_acc: 0.9123\n","Epoch 18/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.2388 - acc: 0.9112 - val_loss: 0.2352 - val_acc: 0.9149\n","Epoch 19/50\n","  640/42085 [..............................] - ETA: 11s - loss: 0.2274 - acc: 0.9266"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 304us/step - loss: 0.2382 - acc: 0.9119 - val_loss: 0.2344 - val_acc: 0.9143\n","Epoch 20/50\n","42085/42085 [==============================] - 13s 302us/step - loss: 0.2355 - acc: 0.9122 - val_loss: 0.2373 - val_acc: 0.9141\n","Epoch 21/50\n","33664/42085 [======================>.......] - ETA: 2s - loss: 0.2263 - acc: 0.9158"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 304us/step - loss: 0.2289 - acc: 0.9141 - val_loss: 0.2354 - val_acc: 0.9146\n","Epoch 22/50\n","42085/42085 [==============================] - 13s 303us/step - loss: 0.2268 - acc: 0.9154 - val_loss: 0.2307 - val_acc: 0.9154\n","Epoch 23/50\n","42085/42085 [==============================] - 13s 305us/step - loss: 0.2243 - acc: 0.9152 - val_loss: 0.2311 - val_acc: 0.9163\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 24/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.2208 - acc: 0.9198 - val_loss: 0.2460 - val_acc: 0.9088\n","Epoch 25/50\n","42085/42085 [==============================] - 13s 304us/step - loss: 0.2161 - acc: 0.9186 - val_loss: 0.2309 - val_acc: 0.9169\n","Epoch 26/50\n","30336/42085 [====================>.........] - ETA: 3s - loss: 0.2150 - acc: 0.9198"],"name":"stdout"},{"output_type":"stream","text":["42085/42085 [==============================] - 13s 303us/step - loss: 0.2140 - acc: 0.9200 - val_loss: 0.2352 - val_acc: 0.9173\n","Epoch 00026: early stopping\n","TEST LOSS: 0.2540745991230011 \t TEST ACCURACY: 0.9107\n","[0.2540745991230011, 0.9107] \n","\n","[[2.20671215e-01 9.26710066e-02 2.39311239e-01 1.20121456e-01\n","  6.12716899e-02 6.40000000e+01 3.20000000e+01 6.40000000e+01\n","  1.28000000e+02 5.12000000e+02 3.00000000e+01]]\n","Train on 46759 samples, validate on 13241 samples\n","Epoch 1/30\n","46759/46759 [==============================] - 5s 97us/step - loss: 0.9162 - acc: 0.6586 - val_loss: 0.5304 - val_acc: 0.7973\n","Epoch 2/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.5166 - acc: 0.8075 - val_loss: 0.4238 - val_acc: 0.8465\n","Epoch 3/30\n","43520/46759 [==========================>...] - ETA: 0s - loss: 0.4457 - acc: 0.8360"],"name":"stdout"},{"output_type":"stream","text":["46759/46759 [==============================] - 4s 81us/step - loss: 0.4434 - acc: 0.8368 - val_loss: 0.3694 - val_acc: 0.8635\n","Epoch 4/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.4025 - acc: 0.8521 - val_loss: 0.3476 - val_acc: 0.8722\n","Epoch 5/30\n","46759/46759 [==============================] - 4s 82us/step - loss: 0.3678 - acc: 0.8642 - val_loss: 0.3350 - val_acc: 0.8756\n","Epoch 6/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.3476 - acc: 0.8728 - val_loss: 0.3038 - val_acc: 0.8876\n","Epoch 7/30\n","46759/46759 [==============================] - 4s 82us/step - loss: 0.3285 - acc: 0.8795 - val_loss: 0.2960 - val_acc: 0.8920\n","Epoch 8/30\n","24064/46759 [==============>...............] - ETA: 1s - loss: 0.3211 - acc: 0.8795"],"name":"stdout"},{"output_type":"stream","text":["46759/46759 [==============================] - 4s 81us/step - loss: 0.3146 - acc: 0.8831 - val_loss: 0.2882 - val_acc: 0.8952\n","Epoch 9/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.3075 - acc: 0.8885 - val_loss: 0.2792 - val_acc: 0.8985\n","Epoch 10/30\n","46759/46759 [==============================] - 4s 82us/step - loss: 0.2954 - acc: 0.8905 - val_loss: 0.2714 - val_acc: 0.9025\n","Epoch 11/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2844 - acc: 0.8937 - val_loss: 0.2705 - val_acc: 0.9018\n","Epoch 12/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2773 - acc: 0.8962 - val_loss: 0.2704 - val_acc: 0.9001\n","Epoch 13/30\n","22016/46759 [=============>................] - ETA: 1s - loss: 0.2663 - acc: 0.9011"],"name":"stdout"},{"output_type":"stream","text":["46759/46759 [==============================] - 4s 81us/step - loss: 0.2686 - acc: 0.8999 - val_loss: 0.2636 - val_acc: 0.9052\n","Epoch 14/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2610 - acc: 0.9029 - val_loss: 0.2578 - val_acc: 0.9058\n","Epoch 15/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2529 - acc: 0.9063 - val_loss: 0.2533 - val_acc: 0.9063\n","Epoch 16/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2497 - acc: 0.9063 - val_loss: 0.2513 - val_acc: 0.9058\n","Epoch 17/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2481 - acc: 0.9083 - val_loss: 0.2437 - val_acc: 0.9097\n","Epoch 18/30\n","20992/46759 [============>.................] - ETA: 1s - loss: 0.2358 - acc: 0.9113"],"name":"stdout"},{"output_type":"stream","text":["46759/46759 [==============================] - 4s 82us/step - loss: 0.2381 - acc: 0.9113 - val_loss: 0.2449 - val_acc: 0.9110\n","Epoch 19/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2341 - acc: 0.9123 - val_loss: 0.2404 - val_acc: 0.9107\n","Epoch 20/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2307 - acc: 0.9135 - val_loss: 0.2422 - val_acc: 0.9114\n","Epoch 21/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2277 - acc: 0.9145 - val_loss: 0.2434 - val_acc: 0.9108\n","Epoch 22/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2223 - acc: 0.9166 - val_loss: 0.2367 - val_acc: 0.9125\n","Epoch 23/30\n","22016/46759 [=============>................] - ETA: 1s - loss: 0.2141 - acc: 0.9214"],"name":"stdout"},{"output_type":"stream","text":["46759/46759 [==============================] - 4s 81us/step - loss: 0.2177 - acc: 0.9188 - val_loss: 0.2405 - val_acc: 0.9133\n","Epoch 24/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2171 - acc: 0.9196 - val_loss: 0.2345 - val_acc: 0.9140\n","Epoch 25/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2125 - acc: 0.9206 - val_loss: 0.2313 - val_acc: 0.9150\n","Epoch 26/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2118 - acc: 0.9205 - val_loss: 0.2326 - val_acc: 0.9151\n","Epoch 27/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2061 - acc: 0.9211 - val_loss: 0.2307 - val_acc: 0.9142\n","Epoch 28/30\n","22016/46759 [=============>................] - ETA: 1s - loss: 0.2041 - acc: 0.9224"],"name":"stdout"},{"output_type":"stream","text":["46759/46759 [==============================] - 4s 81us/step - loss: 0.2031 - acc: 0.9226 - val_loss: 0.2277 - val_acc: 0.9168\n","Epoch 29/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.2021 - acc: 0.9236 - val_loss: 0.2340 - val_acc: 0.9134\n","Epoch 30/30\n","46759/46759 [==============================] - 4s 81us/step - loss: 0.1954 - acc: 0.9265 - val_loss: 0.2305 - val_acc: 0.9144\n","TEST LOSS: 0.242809449839592 \t TEST ACCURACY: 0.9136000000953675\n","[0.242809449839592, 0.9136000000953675] \n","\n","[[1.57901878e-02 6.81571241e-02 1.03674731e-01 1.12215497e-01\n","  4.01578661e-01 1.28000000e+02 6.40000000e+01 1.02400000e+03\n","  2.56000000e+02 2.56000000e+02 3.00000000e+01]]\n","Train on 59052 samples, validate on 948 samples\n","Epoch 1/30\n","21248/59052 [=========>....................] - ETA: 9s - loss: 0.7522 - acc: 0.7260 "],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 14s 242us/step - loss: 0.5542 - acc: 0.7988 - val_loss: 0.3573 - val_acc: 0.8629\n","Epoch 2/30\n","59052/59052 [==============================] - 13s 218us/step - loss: 0.3455 - acc: 0.8733 - val_loss: 0.2874 - val_acc: 0.8840\n","Epoch 3/30\n","25344/59052 [===========>..................] - ETA: 7s - loss: 0.3015 - acc: 0.8890"],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 13s 220us/step - loss: 0.2936 - acc: 0.8914 - val_loss: 0.2698 - val_acc: 0.8966\n","Epoch 4/30\n","59052/59052 [==============================] - 13s 219us/step - loss: 0.2616 - acc: 0.9038 - val_loss: 0.2734 - val_acc: 0.9061\n","Epoch 5/30\n","26112/59052 [============>.................] - ETA: 7s - loss: 0.2296 - acc: 0.9148"],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 13s 217us/step - loss: 0.2330 - acc: 0.9138 - val_loss: 0.2326 - val_acc: 0.9135\n","Epoch 6/30\n","59052/59052 [==============================] - 13s 220us/step - loss: 0.2143 - acc: 0.9200 - val_loss: 0.2314 - val_acc: 0.9167\n","Epoch 7/30\n","26368/59052 [============>.................] - ETA: 7s - loss: 0.1927 - acc: 0.9279"],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 13s 219us/step - loss: 0.1935 - acc: 0.9282 - val_loss: 0.2339 - val_acc: 0.9030\n","Epoch 8/30\n","59052/59052 [==============================] - 13s 218us/step - loss: 0.1739 - acc: 0.9344 - val_loss: 0.2358 - val_acc: 0.9198\n","Epoch 9/30\n","26368/59052 [============>.................] - ETA: 7s - loss: 0.1634 - acc: 0.9373"],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 13s 218us/step - loss: 0.1647 - acc: 0.9377 - val_loss: 0.2349 - val_acc: 0.9241\n","Epoch 10/30\n","59052/59052 [==============================] - 13s 219us/step - loss: 0.1510 - acc: 0.9434 - val_loss: 0.2168 - val_acc: 0.9198\n","Epoch 11/30\n","26112/59052 [============>.................] - ETA: 7s - loss: 0.1355 - acc: 0.9480"],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 13s 218us/step - loss: 0.1360 - acc: 0.9487 - val_loss: 0.2323 - val_acc: 0.9262\n","Epoch 12/30\n","59052/59052 [==============================] - 13s 220us/step - loss: 0.1258 - acc: 0.9524 - val_loss: 0.2261 - val_acc: 0.9209\n","Epoch 13/30\n","26112/59052 [============>.................] - ETA: 7s - loss: 0.1123 - acc: 0.9574"],"name":"stdout"},{"output_type":"stream","text":["59052/59052 [==============================] - 13s 218us/step - loss: 0.1170 - acc: 0.9555 - val_loss: 0.2237 - val_acc: 0.9198\n","Epoch 14/30\n","59052/59052 [==============================] - 13s 218us/step - loss: 0.1090 - acc: 0.9581 - val_loss: 0.2221 - val_acc: 0.9293\n","Epoch 00014: early stopping\n","TEST LOSS: 0.264548934173584 \t TEST ACCURACY: 0.9199\n","[0.264548934173584, 0.9199] \n","\n","[[2.70080808e-01 1.23860569e-01 4.65372588e-01 1.70481736e-01\n","  4.94999054e-02 3.20000000e+01 3.20000000e+01 2.56000000e+02\n","  1.02400000e+03 6.40000000e+01 5.00000000e+01]]\n","Train on 43795 samples, validate on 16205 samples\n","Epoch 1/50\n","12736/43795 [=======>......................] - ETA: 8s - loss: 0.8153 - acc: 0.6917"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 12s 267us/step - loss: 0.6126 - acc: 0.7678 - val_loss: 0.4186 - val_acc: 0.8481\n","Epoch 2/50\n","43795/43795 [==============================] - 11s 251us/step - loss: 0.4288 - acc: 0.8408 - val_loss: 0.3362 - val_acc: 0.8761\n","Epoch 3/50\n","35264/43795 [=======================>......] - ETA: 1s - loss: 0.3691 - acc: 0.8621"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 11s 249us/step - loss: 0.3664 - acc: 0.8629 - val_loss: 0.3261 - val_acc: 0.8765\n","Epoch 4/50\n","43795/43795 [==============================] - 11s 250us/step - loss: 0.3382 - acc: 0.8747 - val_loss: 0.2799 - val_acc: 0.8965\n","Epoch 5/50\n","40000/43795 [==========================>...] - ETA: 0s - loss: 0.3146 - acc: 0.8837"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 11s 251us/step - loss: 0.3151 - acc: 0.8834 - val_loss: 0.2805 - val_acc: 0.8947\n","Epoch 6/50\n","43795/43795 [==============================] - 11s 255us/step - loss: 0.3016 - acc: 0.8885 - val_loss: 0.2669 - val_acc: 0.8997\n","Epoch 7/50\n","40704/43795 [==========================>...] - ETA: 0s - loss: 0.2879 - acc: 0.8914"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 11s 254us/step - loss: 0.2880 - acc: 0.8916 - val_loss: 0.2596 - val_acc: 0.9028\n","Epoch 8/50\n","43795/43795 [==============================] - 11s 252us/step - loss: 0.2744 - acc: 0.8977 - val_loss: 0.2551 - val_acc: 0.9058\n","Epoch 9/50\n","40704/43795 [==========================>...] - ETA: 0s - loss: 0.2676 - acc: 0.8984"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 11s 253us/step - loss: 0.2692 - acc: 0.8975 - val_loss: 0.2615 - val_acc: 0.9011\n","Epoch 10/50\n","43795/43795 [==============================] - 11s 254us/step - loss: 0.2630 - acc: 0.9003 - val_loss: 0.2507 - val_acc: 0.9064\n","Epoch 11/50\n","40320/43795 [==========================>...] - ETA: 0s - loss: 0.2547 - acc: 0.9034"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 11s 252us/step - loss: 0.2548 - acc: 0.9033 - val_loss: 0.2572 - val_acc: 0.9059\n","Epoch 12/50\n","43795/43795 [==============================] - 11s 253us/step - loss: 0.2449 - acc: 0.9059 - val_loss: 0.2601 - val_acc: 0.9055\n","Epoch 13/50\n","40832/43795 [==========================>...] - ETA: 0s - loss: 0.2437 - acc: 0.9077"],"name":"stdout"},{"output_type":"stream","text":["43795/43795 [==============================] - 11s 252us/step - loss: 0.2432 - acc: 0.9078 - val_loss: 0.2592 - val_acc: 0.9032\n","Epoch 14/50\n","43795/43795 [==============================] - 11s 253us/step - loss: 0.2353 - acc: 0.9111 - val_loss: 0.2673 - val_acc: 0.8995\n","Epoch 00014: early stopping\n","TEST LOSS: 0.2822389722108841 \t TEST ACCURACY: 0.8976\n","[0.2822389722108841, 0.8976] \n","\n","[[2.43398226e-01 2.53291905e-02 4.16055226e-03 2.14007437e-01\n","  4.64892246e-01 2.56000000e+02 3.20000000e+01 3.20000000e+01\n","  2.56000000e+02 6.40000000e+01 4.00000000e+01]]\n","Train on 45396 samples, validate on 14604 samples\n","Epoch 1/40\n","15104/45396 [========>.....................] - ETA: 11s - loss: 0.9067 - acc: 0.6662"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 385us/step - loss: 0.6584 - acc: 0.7591 - val_loss: 0.3975 - val_acc: 0.8511\n","Epoch 2/40\n","45396/45396 [==============================] - 17s 368us/step - loss: 0.4224 - acc: 0.8484 - val_loss: 0.3324 - val_acc: 0.8764\n","Epoch 3/40\n","16448/45396 [=========>....................] - ETA: 9s - loss: 0.3656 - acc: 0.8680"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 368us/step - loss: 0.3561 - acc: 0.8712 - val_loss: 0.3089 - val_acc: 0.8854\n","Epoch 4/40\n","45396/45396 [==============================] - 17s 368us/step - loss: 0.3249 - acc: 0.8810 - val_loss: 0.3008 - val_acc: 0.8903\n","Epoch 5/40\n","17408/45396 [==========>...................] - ETA: 9s - loss: 0.2942 - acc: 0.8925"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 368us/step - loss: 0.3006 - acc: 0.8902 - val_loss: 0.3074 - val_acc: 0.8850\n","Epoch 6/40\n","45396/45396 [==============================] - 17s 367us/step - loss: 0.2859 - acc: 0.8953 - val_loss: 0.2709 - val_acc: 0.8982\n","Epoch 7/40\n","17856/45396 [==========>...................] - ETA: 9s - loss: 0.2658 - acc: 0.9005"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 366us/step - loss: 0.2697 - acc: 0.9001 - val_loss: 0.2720 - val_acc: 0.9027\n","Epoch 8/40\n","45396/45396 [==============================] - 17s 366us/step - loss: 0.2620 - acc: 0.9035 - val_loss: 0.2676 - val_acc: 0.9028\n","Epoch 9/40\n","17920/45396 [==========>...................] - ETA: 9s - loss: 0.2492 - acc: 0.9074"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 368us/step - loss: 0.2508 - acc: 0.9082 - val_loss: 0.2604 - val_acc: 0.9022\n","Epoch 10/40\n","45396/45396 [==============================] - 17s 366us/step - loss: 0.2443 - acc: 0.9089 - val_loss: 0.2544 - val_acc: 0.9056\n","Epoch 11/40\n","17408/45396 [==========>...................] - ETA: 9s - loss: 0.2339 - acc: 0.9116"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 368us/step - loss: 0.2384 - acc: 0.9108 - val_loss: 0.2539 - val_acc: 0.9054\n","Epoch 12/40\n","45396/45396 [==============================] - 17s 367us/step - loss: 0.2269 - acc: 0.9146 - val_loss: 0.2521 - val_acc: 0.9087\n","Epoch 13/40\n","16832/45396 [==========>...................] - ETA: 9s - loss: 0.2224 - acc: 0.9177"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 367us/step - loss: 0.2250 - acc: 0.9173 - val_loss: 0.2523 - val_acc: 0.9078\n","Epoch 14/40\n","45396/45396 [==============================] - 17s 367us/step - loss: 0.2167 - acc: 0.9192 - val_loss: 0.2493 - val_acc: 0.9081\n","Epoch 15/40\n","17344/45396 [==========>...................] - ETA: 9s - loss: 0.2095 - acc: 0.9216"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 367us/step - loss: 0.2137 - acc: 0.9204 - val_loss: 0.2627 - val_acc: 0.9061\n","Epoch 16/40\n","45396/45396 [==============================] - 17s 368us/step - loss: 0.2069 - acc: 0.9216 - val_loss: 0.2440 - val_acc: 0.9098\n","Epoch 17/40\n","16960/45396 [==========>...................] - ETA: 9s - loss: 0.2009 - acc: 0.9270"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 366us/step - loss: 0.2031 - acc: 0.9249 - val_loss: 0.2401 - val_acc: 0.9132\n","Epoch 18/40\n","45396/45396 [==============================] - 17s 366us/step - loss: 0.1959 - acc: 0.9266 - val_loss: 0.2479 - val_acc: 0.9116\n","Epoch 19/40\n","17600/45396 [==========>...................] - ETA: 9s - loss: 0.1908 - acc: 0.9299"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 367us/step - loss: 0.1928 - acc: 0.9279 - val_loss: 0.2455 - val_acc: 0.9125\n","Epoch 20/40\n","45396/45396 [==============================] - 17s 367us/step - loss: 0.1911 - acc: 0.9287 - val_loss: 0.2594 - val_acc: 0.9076\n","Epoch 21/40\n","17408/45396 [==========>...................] - ETA: 9s - loss: 0.1815 - acc: 0.9309"],"name":"stdout"},{"output_type":"stream","text":["45396/45396 [==============================] - 17s 368us/step - loss: 0.1853 - acc: 0.9306 - val_loss: 0.2609 - val_acc: 0.9095\n","Epoch 00021: early stopping\n","TEST LOSS: 0.27149430224895477 \t TEST ACCURACY: 0.9082\n","[0.27149430224895477, 0.9082] \n","\n","time elapsed: 19.132859774430592\n"],"name":"stdout"}]},{"metadata":{"id":"YEkLm5RbEadU","colab_type":"text"},"cell_type":"markdown","source":["### Running Optmization"]},{"metadata":{"id":"pm1WPkslAavT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3828},"outputId":"a3141408-7304-46d9-a8ac-63757fb45295"},"cell_type":"code","source":["# optimize mnist model\n","\n","start = time.time()\n","\n","optimize_fashion_mnist.run_optimization(max_iter=10)\n","\n","end = time.time()\n","print(\"time elapsed: {}\".format((end - start)/60))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[6.45471430e-02 5.22864772e-03 7.14942354e-03 5.00000000e-01\n","  3.23694978e-01 6.40000000e+01 3.20000000e+01 6.40000000e+01\n","  1.28000000e+02 5.12000000e+02 3.00000000e+01]]\n","Train on 56127 samples, validate on 3873 samples\n","Epoch 1/30\n","56127/56127 [==============================] - 5s 95us/step - loss: 0.9147 - acc: 0.6635 - val_loss: 0.4944 - val_acc: 0.8120\n","Epoch 2/30\n","56127/56127 [==============================] - 4s 78us/step - loss: 0.5297 - acc: 0.8041 - val_loss: 0.3909 - val_acc: 0.8613\n","Epoch 3/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.4503 - acc: 0.8378 - val_loss: 0.3504 - val_acc: 0.8683\n","Epoch 4/30\n","30208/56127 [===============>..............] - ETA: 1s - loss: 0.4137 - acc: 0.8512"],"name":"stdout"},{"output_type":"stream","text":["56127/56127 [==============================] - 4s 77us/step - loss: 0.4078 - acc: 0.8535 - val_loss: 0.3104 - val_acc: 0.8823\n","Epoch 5/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.3768 - acc: 0.8636 - val_loss: 0.3039 - val_acc: 0.8872\n","Epoch 6/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.3570 - acc: 0.8698 - val_loss: 0.2877 - val_acc: 0.8928\n","Epoch 7/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.3385 - acc: 0.8765 - val_loss: 0.2766 - val_acc: 0.8993\n","Epoch 8/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.3227 - acc: 0.8824 - val_loss: 0.2800 - val_acc: 0.8975\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 9/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.3131 - acc: 0.8858 - val_loss: 0.2640 - val_acc: 0.8985\n","Epoch 10/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.3036 - acc: 0.8903 - val_loss: 0.2669 - val_acc: 0.9006\n","Epoch 11/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2946 - acc: 0.8933 - val_loss: 0.2537 - val_acc: 0.9096\n","Epoch 12/30\n","56127/56127 [==============================] - 4s 78us/step - loss: 0.2919 - acc: 0.8922 - val_loss: 0.2535 - val_acc: 0.9050\n","Epoch 13/30\n","48640/56127 [========================>.....] - ETA: 0s - loss: 0.2825 - acc: 0.8965"],"name":"stdout"},{"output_type":"stream","text":["56127/56127 [==============================] - 4s 75us/step - loss: 0.2821 - acc: 0.8968 - val_loss: 0.2484 - val_acc: 0.9070\n","Epoch 14/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.2756 - acc: 0.8986 - val_loss: 0.2578 - val_acc: 0.9014\n","Epoch 15/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.2671 - acc: 0.9024 - val_loss: 0.2423 - val_acc: 0.9104\n","Epoch 16/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.2628 - acc: 0.9036 - val_loss: 0.2349 - val_acc: 0.9125\n","Epoch 17/30\n","56127/56127 [==============================] - 4s 80us/step - loss: 0.2549 - acc: 0.9075 - val_loss: 0.2281 - val_acc: 0.9125\n","Epoch 18/30\n","  512/56127 [..............................] - ETA: 4s - loss: 0.3201 - acc: 0.8848"],"name":"stdout"},{"output_type":"stream","text":["56127/56127 [==============================] - 4s 77us/step - loss: 0.2530 - acc: 0.9078 - val_loss: 0.2263 - val_acc: 0.9171\n","Epoch 19/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.2503 - acc: 0.9086 - val_loss: 0.2271 - val_acc: 0.9161\n","Epoch 20/30\n","56127/56127 [==============================] - 4s 76us/step - loss: 0.2431 - acc: 0.9097 - val_loss: 0.2257 - val_acc: 0.9138\n","Epoch 21/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2380 - acc: 0.9126 - val_loss: 0.2200 - val_acc: 0.9192\n","Epoch 22/30\n","52736/56127 [===========================>..] - ETA: 0s - loss: 0.2373 - acc: 0.9135"],"name":"stdout"},{"output_type":"stream","text":["56127/56127 [==============================] - 4s 76us/step - loss: 0.2371 - acc: 0.9135 - val_loss: 0.2376 - val_acc: 0.9132\n","Epoch 23/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2283 - acc: 0.9177 - val_loss: 0.2147 - val_acc: 0.9184\n","Epoch 24/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2250 - acc: 0.9170 - val_loss: 0.2170 - val_acc: 0.9202\n","Epoch 25/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2251 - acc: 0.9170 - val_loss: 0.2177 - val_acc: 0.9182\n","Epoch 26/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2213 - acc: 0.9182 - val_loss: 0.2183 - val_acc: 0.9223\n","Epoch 27/30"],"name":"stdout"},{"output_type":"stream","text":["\n","56127/56127 [==============================] - 4s 78us/step - loss: 0.2186 - acc: 0.9192 - val_loss: 0.2127 - val_acc: 0.9220\n","Epoch 28/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2152 - acc: 0.9202 - val_loss: 0.2145 - val_acc: 0.9179\n","Epoch 29/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2125 - acc: 0.9208 - val_loss: 0.2204 - val_acc: 0.9200\n","Epoch 30/30\n","56127/56127 [==============================] - 4s 77us/step - loss: 0.2114 - acc: 0.9225 - val_loss: 0.2062 - val_acc: 0.9264\n","TEST LOSS: 0.23058528215885163 \t TEST ACCURACY: 0.9174000001907349\n","[0.23058528215885163, 0.9174000001907349] \n","\n","[[4.75526551e-02 3.68360236e-01 2.31781140e-01 3.45485889e-01\n","  3.03354981e-01 2.56000000e+02 6.40000000e+01 6.40000000e+01\n","  1.28000000e+02 1.28000000e+02 6.00000000e+01]]\n","Train on 57146 samples, validate on 2854 samples\n","Epoch 1/60\n"," 8064/57146 [===>..........................] - ETA: 17s - loss: 1.3993 - acc: 0.4914"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 17s 291us/step - loss: 0.7380 - acc: 0.7282 - val_loss: 0.4083 - val_acc: 0.8507\n","Epoch 2/60\n","57146/57146 [==============================] - 16s 275us/step - loss: 0.4558 - acc: 0.8316 - val_loss: 0.3488 - val_acc: 0.8665\n","Epoch 3/60\n","23680/57146 [===========>..................] - ETA: 9s - loss: 0.3958 - acc: 0.8549"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 275us/step - loss: 0.3866 - acc: 0.8588 - val_loss: 0.2953 - val_acc: 0.8875\n","Epoch 4/60\n","57146/57146 [==============================] - 16s 274us/step - loss: 0.3494 - acc: 0.8720 - val_loss: 0.2709 - val_acc: 0.8991\n","Epoch 5/60\n","27008/57146 [=============>................] - ETA: 8s - loss: 0.3282 - acc: 0.8796"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 275us/step - loss: 0.3267 - acc: 0.8806 - val_loss: 0.2481 - val_acc: 0.9047\n","Epoch 6/60\n","57146/57146 [==============================] - 16s 275us/step - loss: 0.3060 - acc: 0.8881 - val_loss: 0.2364 - val_acc: 0.9089\n","Epoch 7/60\n","28288/57146 [=============>................] - ETA: 7s - loss: 0.2961 - acc: 0.8916"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 276us/step - loss: 0.2971 - acc: 0.8918 - val_loss: 0.2407 - val_acc: 0.9145\n","Epoch 8/60\n","57146/57146 [==============================] - 16s 275us/step - loss: 0.2872 - acc: 0.8943 - val_loss: 0.2344 - val_acc: 0.9114\n","Epoch 9/60\n","28288/57146 [=============>................] - ETA: 7s - loss: 0.2793 - acc: 0.8979"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 276us/step - loss: 0.2792 - acc: 0.8973 - val_loss: 0.2262 - val_acc: 0.9159\n","Epoch 10/60\n","57146/57146 [==============================] - 16s 275us/step - loss: 0.2750 - acc: 0.8991 - val_loss: 0.2315 - val_acc: 0.9093\n","Epoch 11/60\n","28032/57146 [=============>................] - ETA: 7s - loss: 0.2659 - acc: 0.9023"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 274us/step - loss: 0.2674 - acc: 0.9019 - val_loss: 0.2231 - val_acc: 0.9166\n","Epoch 12/60\n","57146/57146 [==============================] - 16s 274us/step - loss: 0.2623 - acc: 0.9036 - val_loss: 0.2374 - val_acc: 0.9103\n","Epoch 13/60\n","27776/57146 [=============>................] - ETA: 7s - loss: 0.2524 - acc: 0.9054"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 276us/step - loss: 0.2564 - acc: 0.9048 - val_loss: 0.2127 - val_acc: 0.9226\n","Epoch 14/60\n","57146/57146 [==============================] - 16s 275us/step - loss: 0.2525 - acc: 0.9074 - val_loss: 0.2096 - val_acc: 0.9261\n","Epoch 15/60\n","28032/57146 [=============>................] - ETA: 7s - loss: 0.2480 - acc: 0.9074"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 277us/step - loss: 0.2487 - acc: 0.9080 - val_loss: 0.2143 - val_acc: 0.9194\n","Epoch 16/60\n","57146/57146 [==============================] - 16s 276us/step - loss: 0.2446 - acc: 0.9097 - val_loss: 0.2221 - val_acc: 0.9177\n","Epoch 17/60\n","28032/57146 [=============>................] - ETA: 7s - loss: 0.2418 - acc: 0.9115"],"name":"stdout"},{"output_type":"stream","text":["57146/57146 [==============================] - 16s 276us/step - loss: 0.2415 - acc: 0.9109 - val_loss: 0.2283 - val_acc: 0.9135\n","Epoch 18/60\n","57146/57146 [==============================] - 16s 275us/step - loss: 0.2383 - acc: 0.9113 - val_loss: 0.2132 - val_acc: 0.9173\n","Epoch 00018: early stopping\n","TEST LOSS: 0.24155028431415557 \t TEST ACCURACY: 0.9134\n","[0.24155028431415557, 0.9134] \n","\n","[[2.75940890e-01 2.34704421e-02 2.90895546e-01 1.99511703e-01\n","  2.66071771e-01 5.12000000e+02 6.40000000e+01 6.40000000e+01\n","  2.56000000e+02 5.12000000e+02 4.00000000e+01]]\n","Train on 43443 samples, validate on 16557 samples\n","Epoch 1/40\n","22528/43443 [==============>...............]"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 22s 506us/step - loss: 0.8810 - acc: 0.6782 - val_loss: 0.4943 - val_acc: 0.8200\n","Epoch 2/40\n","43443/43443 [==============================] - 19s 440us/step - loss: 0.5097 - acc: 0.8132 - val_loss: 0.4056 - val_acc: 0.8476\n","Epoch 3/40\n","43443/43443 [==============================] - 19s 440us/step - loss: 0.4368 - acc: 0.8405 - val_loss: 0.3587 - val_acc: 0.8644\n","Epoch 4/40\n","28160/43443 [==================>...........] - ETA: 6s - loss: 0.4039 - acc: 0.8475"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 443us/step - loss: 0.3997 - acc: 0.8493 - val_loss: 0.3309 - val_acc: 0.8800\n","Epoch 5/40\n","43443/43443 [==============================] - 19s 441us/step - loss: 0.3722 - acc: 0.8628 - val_loss: 0.3173 - val_acc: 0.8790\n","Epoch 6/40\n","43443/43443 [==============================] - 19s 442us/step - loss: 0.3471 - acc: 0.8713 - val_loss: 0.3025 - val_acc: 0.8877\n","Epoch 7/40\n","33280/43443 [=====================>........] - ETA: 3s - loss: 0.3412 - acc: 0.8732"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 441us/step - loss: 0.3381 - acc: 0.8744 - val_loss: 0.2880 - val_acc: 0.8910\n","Epoch 8/40\n","43443/43443 [==============================] - 19s 439us/step - loss: 0.3213 - acc: 0.8797 - val_loss: 0.2790 - val_acc: 0.8945\n","Epoch 9/40\n","43443/43443 [==============================] - 19s 441us/step - loss: 0.3081 - acc: 0.8843 - val_loss: 0.2913 - val_acc: 0.8905\n","Epoch 10/40\n","26112/43443 [=================>............] - ETA: 6s - loss: 0.2992 - acc: 0.8874"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 439us/step - loss: 0.2997 - acc: 0.8872 - val_loss: 0.2788 - val_acc: 0.8961\n","Epoch 11/40\n","43443/43443 [==============================] - 19s 442us/step - loss: 0.2917 - acc: 0.8904 - val_loss: 0.2608 - val_acc: 0.9008\n","Epoch 12/40\n","43443/43443 [==============================] - 19s 441us/step - loss: 0.2766 - acc: 0.8950 - val_loss: 0.2586 - val_acc: 0.9055\n","Epoch 13/40\n","31232/43443 [====================>.........] - ETA: 4s - loss: 0.2683 - acc: 0.8981"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 441us/step - loss: 0.2706 - acc: 0.8987 - val_loss: 0.2546 - val_acc: 0.9037\n","Epoch 14/40\n","43443/43443 [==============================] - 19s 439us/step - loss: 0.2636 - acc: 0.9012 - val_loss: 0.2544 - val_acc: 0.9065\n","Epoch 15/40\n","43443/43443 [==============================] - 19s 439us/step - loss: 0.2566 - acc: 0.9032 - val_loss: 0.2563 - val_acc: 0.9036\n","Epoch 16/40\n","28672/43443 [==================>...........] - ETA: 5s - loss: 0.2582 - acc: 0.9031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 440us/step - loss: 0.2548 - acc: 0.9050 - val_loss: 0.2564 - val_acc: 0.9029\n","Epoch 17/40\n","43443/43443 [==============================] - 19s 441us/step - loss: 0.2503 - acc: 0.9054 - val_loss: 0.2412 - val_acc: 0.9091\n","Epoch 18/40\n","43443/43443 [==============================] - 19s 442us/step - loss: 0.2443 - acc: 0.9082 - val_loss: 0.2447 - val_acc: 0.9094\n","Epoch 19/40\n","32768/43443 [=====================>........] - ETA: 4s - loss: 0.2328 - acc: 0.9121"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 439us/step - loss: 0.2344 - acc: 0.9119 - val_loss: 0.2406 - val_acc: 0.9113\n","Epoch 20/40\n","43443/43443 [==============================] - 19s 440us/step - loss: 0.2327 - acc: 0.9128 - val_loss: 0.2352 - val_acc: 0.9114\n","Epoch 21/40\n","43443/43443 [==============================] - 19s 440us/step - loss: 0.2255 - acc: 0.9132 - val_loss: 0.2353 - val_acc: 0.9135\n","Epoch 22/40\n","31232/43443 [====================>.........] - ETA: 4s - loss: 0.2270 - acc: 0.9145"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 439us/step - loss: 0.2279 - acc: 0.9143 - val_loss: 0.2327 - val_acc: 0.9131\n","Epoch 23/40\n","43443/43443 [==============================] - 19s 439us/step - loss: 0.2199 - acc: 0.9178 - val_loss: 0.2470 - val_acc: 0.9092\n","Epoch 24/40\n","43443/43443 [==============================] - 19s 440us/step - loss: 0.2180 - acc: 0.9178 - val_loss: 0.2346 - val_acc: 0.9123\n","Epoch 25/40\n","31232/43443 [====================>.........] - ETA: 4s - loss: 0.2103 - acc: 0.9199"],"name":"stdout"},{"output_type":"stream","text":["43443/43443 [==============================] - 19s 440us/step - loss: 0.2150 - acc: 0.9184 - val_loss: 0.2347 - val_acc: 0.9134\n","Epoch 26/40\n","43443/43443 [==============================] - 19s 440us/step - loss: 0.2117 - acc: 0.9197 - val_loss: 0.2349 - val_acc: 0.9148\n","Epoch 00026: early stopping\n","TEST LOSS: 0.2508865385532379 \t TEST ACCURACY: 0.9087999998092652\n","[0.2508865385532379, 0.9087999998092652] \n","\n","[[8.17081805e-02 1.13056806e-01 3.89908568e-01 2.29191017e-01\n","  1.33192418e-01 1.60000000e+01 3.20000000e+01 5.12000000e+02\n","  3.20000000e+01 5.12000000e+02 5.00000000e+01]]\n","Train on 55097 samples, validate on 4903 samples\n","Epoch 1/50\n","55097/55097 [==============================] - 5s 88us/step - loss: 0.9149 - acc: 0.6619 - val_loss: 0.5372 - val_acc: 0.7977\n","Epoch 2/50\n","38400/55097 [===================>..........] - ETA: 0s - loss: 0.5997 - acc: 0.7742"],"name":"stdout"},{"output_type":"stream","text":["55097/55097 [==============================] - 3s 60us/step - loss: 0.5841 - acc: 0.7807 - val_loss: 0.4424 - val_acc: 0.8409\n","Epoch 3/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.5104 - acc: 0.8131 - val_loss: 0.3947 - val_acc: 0.8572\n","Epoch 4/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.4645 - acc: 0.8306 - val_loss: 0.3629 - val_acc: 0.8642\n","Epoch 5/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.4339 - acc: 0.8425 - val_loss: 0.3419 - val_acc: 0.8744\n","Epoch 6/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.4048 - acc: 0.8520 - val_loss: 0.3343 - val_acc: 0.8801\n","Epoch 7/50\n"," 5632/55097 [==>...........................] - ETA: 2s - loss: 0.3898 - acc: 0.8560"],"name":"stdout"},{"output_type":"stream","text":["55097/55097 [==============================] - 3s 60us/step - loss: 0.3865 - acc: 0.8593 - val_loss: 0.3133 - val_acc: 0.8827\n","Epoch 8/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.3681 - acc: 0.8651 - val_loss: 0.3049 - val_acc: 0.8874\n","Epoch 9/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.3524 - acc: 0.8707 - val_loss: 0.2877 - val_acc: 0.8913\n","Epoch 10/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.3433 - acc: 0.8737 - val_loss: 0.2807 - val_acc: 0.8956\n","Epoch 11/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.3321 - acc: 0.8788 - val_loss: 0.2831 - val_acc: 0.8944\n","Epoch 12/50\n"," 1536/55097 [..............................] - ETA: 3s - loss: 0.3431 - acc: 0.8737"],"name":"stdout"},{"output_type":"stream","text":["55097/55097 [==============================] - 3s 60us/step - loss: 0.3233 - acc: 0.8824 - val_loss: 0.2678 - val_acc: 0.9001\n","Epoch 13/50\n","55097/55097 [==============================] - 3s 59us/step - loss: 0.3182 - acc: 0.8838 - val_loss: 0.2700 - val_acc: 0.8978\n","Epoch 14/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.3103 - acc: 0.8885 - val_loss: 0.2673 - val_acc: 0.8990\n","Epoch 15/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.3014 - acc: 0.8906 - val_loss: 0.2557 - val_acc: 0.9058\n","Epoch 16/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2946 - acc: 0.8926 - val_loss: 0.2560 - val_acc: 0.9033\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 17/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2898 - acc: 0.8945 - val_loss: 0.2450 - val_acc: 0.9082\n","Epoch 18/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2860 - acc: 0.8954 - val_loss: 0.2452 - val_acc: 0.9101\n","Epoch 19/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2774 - acc: 0.8984 - val_loss: 0.2423 - val_acc: 0.9092\n","Epoch 20/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2764 - acc: 0.8990 - val_loss: 0.2493 - val_acc: 0.9068\n","Epoch 21/50\n","51712/55097 [===========================>..] - ETA: 0s - loss: 0.2693 - acc: 0.9005"],"name":"stdout"},{"output_type":"stream","text":["55097/55097 [==============================] - 3s 60us/step - loss: 0.2697 - acc: 0.9004 - val_loss: 0.2373 - val_acc: 0.9111\n","Epoch 22/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2687 - acc: 0.9015 - val_loss: 0.2349 - val_acc: 0.9088\n","Epoch 23/50\n","55097/55097 [==============================] - 3s 60us/step - loss: 0.2630 - acc: 0.9025 - val_loss: 0.2335 - val_acc: 0.9147\n","Epoch 24/50\n","45568/55097 [=======================>......] - ETA: 0s - loss: 0.2564 - acc: 0.9051"],"name":"stdout"}]},{"metadata":{"id":"pjAkQ2HY12W4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":272},"outputId":"acf395c5-de7e-42fd-a6d9-18b1283e12c3","executionInfo":{"status":"ok","timestamp":1527783766526,"user_tz":-60,"elapsed":628,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["# Show optimized fashion mnist model\n","\n","\n","print(\"\"\"\n","Optimized Parameters:\\n \n","\\t{0}: {1}\n","\\t{2}: {3}\n","\\t{4}: {5}\n","\\t{6}: {7}\n","\\t{8}: {9}\n","\\t{10}: {11}\n","\\t{12}: {13}\n","\\t{14}: {15}\n","\\t{16}: {17}\n","\\t{18}: {19}\n","\\t{20}: {21}\n","\"\"\".format(bounds[0][\"name\"], optimize_fashion_mnist.x_opt[0],\n","           bounds[1][\"name\"], optimize_fashion_mnist.x_opt[1],\n","           bounds[2][\"name\"], optimize_fashion_mnist.x_opt[2],\n","           bounds[3][\"name\"], optimize_fashion_mnist.x_opt[3],\n","           bounds[4][\"name\"], optimize_fashion_mnist.x_opt[4],\n","           bounds[5][\"name\"], optimize_fashion_mnist.x_opt[5],\n","           bounds[6][\"name\"], optimize_fashion_mnist.x_opt[6],\n","           bounds[7][\"name\"], optimize_fashion_mnist.x_opt[7],\n","           bounds[8][\"name\"], optimize_fashion_mnist.x_opt[8],\n","           bounds[9][\"name\"], optimize_fashion_mnist.x_opt[9],\n","           bounds[10][\"name\"], optimize_fashion_mnist.x_opt[10]))\n","\n","print(\"optimized loss: {0}\".format(optimize_fashion_mnist.fx_opt))"],"execution_count":64,"outputs":[{"output_type":"stream","text":["\n","Optimized Parameters: \n","\tvalidation_split: 0.09159103468674865\n","\tl1_drop: 0.20775426571420313\n","\tl2_drop: 0.29613491912015927\n","\tl3_drop: 0.06437685604642024\n","\tl4_drop: 0.3545708336915873\n","\tl1_out: 16.0\n","\tl2_out: 128.0\n","\tl3_out: 128.0\n","\tl4_out: 64.0\n","\tbatch_size: 256.0\n","\tepochs: 60.0\n","\n","optimized loss: 0.22566337995529176\n"],"name":"stdout"}]},{"metadata":{"id":"f9pOA7MsJqT2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":232},"outputId":"59f8bbaa-7c91-4b4c-e2cd-c2316bb5565c","executionInfo":{"status":"error","timestamp":1527803753635,"user_tz":-60,"elapsed":512,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["fashion_mnist_opt = FASHION_MNIST(img_rows=28, \n","                              img_cols=28,\n","                              num_classes=10,\n","                              l1_out = int(optimize_fashion_mnist.x_opt[5]),\n","                              l2_out = int(optimize_fashion_mnist.x_opt[6]),\n","                              l3_out = int(optimize_fashion_mnist.x_opt[7]),\n","                              l4_out = int(optimize_fashion_mnist.x_opt[8]),\n","                              l1_drop = float(optimize_fashion_mnist.x_opt[1]),\n","                              l2_drop = float(optimize_fashion_mnist.x_opt[2]),\n","                              l3_drop = float(optimize_fashion_mnist.x_opt[3]),\n","                              l4_drop = float(optimize_fashion_mnist.x_opt[4]),\n","                              batch_size = int(optimize_fashion_mnist.x_opt[9]),\n","                              epochs = int(optimize_fashion_mnist.x_opt[10]),\n","                              validation_split = float(optimize_fashion_mnist.x_opt[0]))\n","\n","\n","history = fashion_mnist_opt.fit()\n","\n","evaluation = fashion_mnist_opt.evaluate()"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a4c56fd1d20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mimg_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               \u001b[0ml1_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_fashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0ml2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_fashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0ml3_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_fashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'optimize_fashion_mnist' is not defined"]}]},{"metadata":{"id":"hWqa5Sqw6qpd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":955},"outputId":"b731989e-540e-4b64-e457-b1e5fb448f0d","executionInfo":{"status":"ok","timestamp":1527784186642,"user_tz":-60,"elapsed":131180,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["evaluation = run_fashion_mnist(img_rows=28, \n","                              img_cols=28,\n","                              num_classes=10,\n","                              l1_out = int(optimize_fashion_mnist.x_opt[5]),\n","                              l2_out = int(optimize_fashion_mnist.x_opt[6]),\n","                              l3_out = int(optimize_fashion_mnist.x_opt[7]),\n","                              l4_out = int(optimize_fashion_mnist.x_opt[8]),\n","                              l1_drop = float(optimize_fashion_mnist.x_opt[1]),\n","                              l2_drop = float(optimize_fashion_mnist.x_opt[2]),\n","                              l3_drop = float(optimize_fashion_mnist.x_opt[3]),\n","                              l4_drop = float(optimize_fashion_mnist.x_opt[4]),\n","                              batch_size = int(optimize_fashion_mnist.x_opt[9]),\n","                              epochs = int(optimize_fashion_mnist.x_opt[10]),\n","                              validation_split = float(optimize_fashion_mnist.x_opt[0]))\n"],"execution_count":68,"outputs":[{"output_type":"stream","text":["Train on 54504 samples, validate on 5496 samples\n","Epoch 1/60\n","54504/54504 [==============================] - 9s 171us/step - loss: 0.8382 - acc: 0.6924 - val_loss: 0.5015 - val_acc: 0.8153\n","Epoch 2/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.5250 - acc: 0.8077 - val_loss: 0.4088 - val_acc: 0.8437\n","Epoch 3/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.4591 - acc: 0.8340 - val_loss: 0.3592 - val_acc: 0.8701\n","Epoch 4/60\n","43264/54504 [======================>.......] - ETA: 0s - loss: 0.4139 - acc: 0.8502"],"name":"stdout"},{"output_type":"stream","text":["54504/54504 [==============================] - 5s 88us/step - loss: 0.4123 - acc: 0.8504 - val_loss: 0.3341 - val_acc: 0.8774\n","Epoch 5/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.3818 - acc: 0.8629 - val_loss: 0.3123 - val_acc: 0.8866\n","Epoch 6/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.3569 - acc: 0.8711 - val_loss: 0.2908 - val_acc: 0.8934\n","Epoch 7/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.3407 - acc: 0.8802 - val_loss: 0.2766 - val_acc: 0.8990\n","Epoch 8/60\n","20992/54504 [==========>...................] - ETA: 2s - loss: 0.3212 - acc: 0.8861"],"name":"stdout"},{"output_type":"stream","text":["54504/54504 [==============================] - 5s 87us/step - loss: 0.3222 - acc: 0.8849 - val_loss: 0.2684 - val_acc: 0.9030\n","Epoch 9/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.3064 - acc: 0.8889 - val_loss: 0.2611 - val_acc: 0.9019\n","Epoch 10/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.2994 - acc: 0.8925 - val_loss: 0.2607 - val_acc: 0.9034\n","Epoch 11/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2867 - acc: 0.8964 - val_loss: 0.2495 - val_acc: 0.9052\n","Epoch 12/60\n","17664/54504 [========>.....................] - ETA: 3s - loss: 0.2737 - acc: 0.9023"],"name":"stdout"},{"output_type":"stream","text":["54504/54504 [==============================] - 5s 87us/step - loss: 0.2781 - acc: 0.9002 - val_loss: 0.2441 - val_acc: 0.9110\n","Epoch 13/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2675 - acc: 0.9033 - val_loss: 0.2421 - val_acc: 0.9108\n","Epoch 14/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.2625 - acc: 0.9046 - val_loss: 0.2348 - val_acc: 0.9116\n","Epoch 15/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2567 - acc: 0.9066 - val_loss: 0.2441 - val_acc: 0.9107\n","Epoch 16/60\n","14080/54504 [======>.......................] - ETA: 3s - loss: 0.2523 - acc: 0.9073"],"name":"stdout"},{"output_type":"stream","text":["54504/54504 [==============================] - 5s 88us/step - loss: 0.2496 - acc: 0.9090 - val_loss: 0.2376 - val_acc: 0.9107\n","Epoch 17/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2422 - acc: 0.9099 - val_loss: 0.2371 - val_acc: 0.9138\n","Epoch 18/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.2379 - acc: 0.9138 - val_loss: 0.2307 - val_acc: 0.9143\n","Epoch 19/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2353 - acc: 0.9131 - val_loss: 0.2232 - val_acc: 0.9179\n","Epoch 20/60\n","13312/54504 [======>.......................] - ETA: 3s - loss: 0.2256 - acc: 0.9188"],"name":"stdout"},{"output_type":"stream","text":["54504/54504 [==============================] - 5s 88us/step - loss: 0.2255 - acc: 0.9175 - val_loss: 0.2248 - val_acc: 0.9118\n","Epoch 21/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2230 - acc: 0.9182 - val_loss: 0.2225 - val_acc: 0.9176\n","Epoch 22/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2185 - acc: 0.9196 - val_loss: 0.2131 - val_acc: 0.9179\n","Epoch 23/60\n","54504/54504 [==============================] - 5s 88us/step - loss: 0.2137 - acc: 0.9215 - val_loss: 0.2172 - val_acc: 0.9198\n","Epoch 24/60\n","14080/54504 [======>.......................] - ETA: 3s - loss: 0.2039 - acc: 0.9268"],"name":"stdout"},{"output_type":"stream","text":["54504/54504 [==============================] - 5s 88us/step - loss: 0.2081 - acc: 0.9241 - val_loss: 0.2188 - val_acc: 0.9179\n","Epoch 25/60\n","54504/54504 [==============================] - 5s 87us/step - loss: 0.2088 - acc: 0.9228 - val_loss: 0.2214 - val_acc: 0.9187\n","Epoch 26/60\n","54504/54504 [==============================] - 5s 89us/step - loss: 0.2056 - acc: 0.9241 - val_loss: 0.2185 - val_acc: 0.9181\n","Epoch 00026: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"3frKxUinCt22","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"b083aa7a-3820-4535-ed30-673de59eec88","executionInfo":{"status":"ok","timestamp":1527784337460,"user_tz":-60,"elapsed":623,"user":{"displayName":"Niall Turbitt","photoUrl":"//lh4.googleusercontent.com/-8T4clQIdx1Y/AAAAAAAAAAI/AAAAAAAAAKI/oERGPawEbK8/s50-c-k-no/photo.jpg","userId":"113020036098296333682"}}},"cell_type":"code","source":["evaluation"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.23914691522121428, 0.9144]"]},"metadata":{"tags":[]},"execution_count":69}]},{"metadata":{"id":"95vesOcGA_Ya","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["history = model.fit(X_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(X_val, y_val))\n","\n","test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)"],"execution_count":0,"outputs":[]}]}